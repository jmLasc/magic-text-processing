{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will evaluate the text using TFIDF and some other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from basic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = fetchData(\"cards.json\")\n",
    "data = cleanData(raw)\n",
    "colors = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeBucket(listColor): # This takes ONE list, e.g. 'W'\n",
    "    tokensList = []\n",
    "    means = [] # This function also gets the mean!!\n",
    "\n",
    "    for cardDict in listColor:\n",
    "        if 'oracle_text' in list(cardDict.keys()):\n",
    "            tokens = nltk.word_tokenize(cardDict['oracle_text'])\n",
    "            for t in tokens:\n",
    "                tokensList.append(t)\n",
    "            means.append(len(tokens))\n",
    "\n",
    "    print(\"Mean = \" + str(np.mean(means)))\n",
    "\n",
    "    return tokensList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "Mean = 31.297722705961153\n",
      "U\n",
      "Mean = 34.77502984820058\n",
      "B\n",
      "Mean = 33.60504342017368\n",
      "R\n",
      "Mean = 33.38563423331635\n",
      "G\n",
      "Mean = 32.880027619540826\n",
      "colorless\n",
      "Mean = 34.478184991274\n"
     ]
    }
   ],
   "source": [
    "tokens = [] # will be a list(list(str))\n",
    "\n",
    "for i, key in enumerate(data.keys()):\n",
    "    print(colors[i])\n",
    "    tokens.append(tokenizeBucket(data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = [\"{\", \"}\", 'W', 'U', 'B', 'R', 'G', \"T\", \"â€”\", \"TK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_common_ngrams(tokenlist, ngram, qty):\n",
    "\n",
    "    tokenlist = [w for w in tokenlist if w not in stoplist] \n",
    "\n",
    "    raw = nltk.ngrams(tokenlist, ngram)\n",
    "    fdist = nltk.FreqDist(raw)\n",
    "    for pair in fdist.most_common(qty): # print n most common bigrams\n",
    "        print(pair[0]) # most_common gives list(tuple(tuple(str, str), int)) so this is how we extract the words2\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "('until', 'end', 'of', 'turn')\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('end', 'of', 'turn', '.')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "('a', '+1/+1', 'counter', 'on')\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('.', 'When', 'CARDNAME', 'enters')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('put', 'a', '+1/+1', 'counter')\n",
      "('damage', 'that', 'would', 'be')\n",
      "('that', 'would', 'be', 'dealt')\n",
      "(',', 'put', 'a', '+1/+1')\n",
      "('would', 'be', 'dealt', 'to')\n",
      "('from', 'your', 'graveyard', 'to')\n",
      "\n",
      "U\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "('until', 'end', 'of', 'turn')\n",
      "('end', 'of', 'turn', '.')\n",
      "('its', 'owner', \"'s\", 'hand')\n",
      "('to', 'its', 'owner', \"'s\")\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('owner', \"'s\", 'hand', '.')\n",
      "('draw', 'a', 'card', '.')\n",
      "('ca', \"n't\", 'be', 'blocked')\n",
      "('Draw', 'a', 'card', '.')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('of', 'your', 'library', '.')\n",
      "('.', 'If', 'you', 'do')\n",
      "\n",
      "B\n",
      "('until', 'end', 'of', 'turn')\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('end', 'of', 'turn', '.')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('from', 'your', 'graveyard', 'to')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('card', 'from', 'your', 'graveyard')\n",
      "('a', '+1/+1', 'counter', 'on')\n",
      "('.', 'When', 'CARDNAME', 'enters')\n",
      "('.', 'If', 'you', 'do')\n",
      "('.', 'At', 'the', 'beginning')\n",
      "('ca', \"n't\", 'be', 'blocked')\n",
      "('beginning', 'of', 'your', 'upkeep')\n",
      "\n",
      "R\n",
      "('until', 'end', 'of', 'turn')\n",
      "('end', 'of', 'turn', '.')\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "('damage', 'to', 'any', 'target')\n",
      "('to', 'any', 'target', '.')\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('deals', '1', 'damage', 'to')\n",
      "('damage', 'to', 'target', 'creature')\n",
      "('deals', '2', 'damage', 'to')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('.', 'If', 'you', 'do')\n",
      "('CARDNAME', 'deals', '1', 'damage')\n",
      "('.', 'When', 'CARDNAME', 'enters')\n",
      "\n",
      "G\n",
      "('until', 'end', 'of', 'turn')\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('end', 'of', 'turn', '.')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "('a', '+1/+1', 'counter', 'on')\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('.', 'When', 'CARDNAME', 'enters')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('put', 'a', '+1/+1', 'counter')\n",
      "(',', 'then', 'shuffle', '.')\n",
      "(',', 'put', 'a', '+1/+1')\n",
      "('+1/+1', 'counters', 'on', 'it')\n",
      "('enters', 'the', 'battlefield', 'with')\n",
      "('of', 'your', 'library', '.')\n",
      "\n",
      "colorless\n",
      "('CARDNAME', 'enters', 'the', 'battlefield')\n",
      "('until', 'end', 'of', 'turn')\n",
      "('enters', 'the', 'battlefield', ',')\n",
      "('At', 'the', 'beginning', 'of')\n",
      "('end', 'of', 'turn', '.')\n",
      "(':', 'Add', 'C', '.')\n",
      "(',', 'Sacrifice', 'CARDNAME', ':')\n",
      "('the', 'beginning', 'of', 'your')\n",
      "('Add', 'one', 'mana', 'of')\n",
      "('.', 'At', 'the', 'beginning')\n",
      "(':', 'Add', 'one', 'mana')\n",
      "('one', 'mana', 'of', 'any')\n",
      "('.', ':', 'Add', 'C')\n",
      "('mana', 'of', 'any', 'color')\n",
      "('When', 'CARDNAME', 'enters', 'the')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tl in enumerate(tokens):\n",
    "    print(colors[i])\n",
    "    print_common_ngrams(tl, 4, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_collocations(tokenlist, n, f):\n",
    "    find = nltk.collocations.BigramCollocationFinder.from_words(tokenlist)\n",
    "    find.apply_freq_filter(f) \n",
    "    best = find.nbest(nltk.collocations.BigramAssocMeasures().pmi, 100)\n",
    "\n",
    "    for pair in best:\n",
    "        if bool(re.search('^[A-Z].*', pair[0])) and bool(re.search('^[A-Z].*', pair[1])):\n",
    "            best.remove(pair)\n",
    "\n",
    "    print(\"** Common Collocations **\")\n",
    "    for i, pair in enumerate(best):\n",
    "        if i == n:\n",
    "            break\n",
    "        print(pair)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "** Common Collocations **\n",
      "('Skipped', 'chapters')\n",
      "('lasts', 'indefinitely')\n",
      "('legend', 'rule')\n",
      "('square', 'brackets')\n",
      "('Shattered', 'Seraph')\n",
      "('Spell', 'mastery')\n",
      "('summoning', 'sickness')\n",
      "('Basic', 'landcycling')\n",
      "('Fateful', 'hour')\n",
      "('counts', 'toward')\n",
      "('final', 'chapter')\n",
      "('Totem', 'armor')\n",
      "('Mirrodin', '!')\n",
      "('Battle', 'cry')\n",
      "('Friends', 'forever')\n",
      "\n",
      "U\n",
      "** Common Collocations **\n",
      "('Timing', 'rules')\n",
      "('Shattered', 'Seraph')\n",
      "('Spell', 'mastery')\n",
      "('Totem', 'armor')\n",
      "('chaos', 'ensues')\n",
      "('wears', 'off')\n",
      "('Friends', 'forever')\n",
      "('counts', 'toward')\n",
      "('friends', 'forever')\n",
      "('square', 'brackets')\n",
      "('Basic', 'landcycling')\n",
      "('crews', 'Vehicles')\n",
      "('Secret', 'council')\n",
      "('Eldrazi', 'Scion')\n",
      "('done', 'activating')\n",
      "\n",
      "B\n",
      "** Common Collocations **\n",
      "('Basic', 'landcycling')\n",
      "('Fathomless', 'descent')\n",
      "('Kher', 'Keep')\n",
      "('Spell', 'mastery')\n",
      "('done', 'activating')\n",
      "('lasts', 'indefinitely')\n",
      "('square', 'brackets')\n",
      "('chaos', 'ensues')\n",
      "('high', 'bid')\n",
      "('postcombat', 'main')\n",
      "('precombat', 'main')\n",
      "('effect', 'lasts')\n",
      "('effect', 'reduces')\n",
      "('counts', 'toward')\n",
      "('phases', 'out')\n",
      "\n",
      "R\n",
      "** Common Collocations **\n",
      "('Young', 'Hero')\n",
      "('counts', 'toward')\n",
      "('Basic', 'landcycling')\n",
      "('Rakish', 'Revelers')\n",
      "('Spell', 'mastery')\n",
      "('legend', 'rule')\n",
      "('summoning', 'sickness')\n",
      "('Pack', 'tactics')\n",
      "('done', 'activating')\n",
      "('chaos', 'ensues')\n",
      "('lasts', 'indefinitely')\n",
      "('Battle', 'cry')\n",
      "('Friends', 'forever')\n",
      "('friends', 'forever')\n",
      "('Mirrodin', '!')\n",
      "\n",
      "G\n",
      "** Common Collocations **\n",
      "('Spell', 'mastery')\n",
      "('Three', 'Pigs')\n",
      "('booster', 'pack')\n",
      "('Pack', 'tactics')\n",
      "('chaos', 'ensues')\n",
      "('Basic', 'landcycling')\n",
      "('Totem', 'armor')\n",
      "('lasts', 'indefinitely')\n",
      "('summoning', 'sickness')\n",
      "('counts', 'toward')\n",
      "('Ring', 'tempts')\n",
      "('declare', 'attackers')\n",
      "('Pigs', 'spellbook')\n",
      "('19', '|')\n",
      "('command', 'zone')\n",
      "\n",
      "colorless\n",
      "** Common Collocations **\n",
      "('Deep', 'Mines')\n",
      "('clockwise', 'around')\n",
      "('done', 'activating')\n",
      "('goes', 'counterclockwise')\n",
      "('now', 'goes')\n",
      "('proceeded', 'clockwise')\n",
      "('originally', 'printed')\n",
      "('Power', 'Plant')\n",
      "('Time', 'Lord')\n",
      "('while', 'casting')\n",
      "('Hidden', 'agenda')\n",
      "('booster', 'pack')\n",
      "('lasts', 'indefinitely')\n",
      "('kind', 'already')\n",
      "('Living', 'weapon')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, tl in enumerate(tokens):\n",
    "    print(colors[i])\n",
    "    print_collocations(tl, 15, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'card'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making tdidf model + vectorizing \n",
    "tfidf_vectorizer = TfidfVectorizer(input='filename', stop_words='english')\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(list_txts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
